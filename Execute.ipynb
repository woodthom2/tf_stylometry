{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/thomas/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_folder = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from text_cnn import TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, pickle as pkl\n",
    "with gzip.GzipFile(\"data/abridged_index2word.pkl.gz\", \"rb\") as f:\n",
    "    abridged_index2word = pkl.load(f)\n",
    "with gzip.GzipFile(\"data/abridged_word2index.pkl.gz\", \"rb\") as f:\n",
    "    abridged_word2index = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = TextCNN(\n",
    "            sequence_length=SAMPLE_LENGTH,\n",
    "            num_classes=3,\n",
    "            vocab_size=len(abridged_index2word),\n",
    "            embedding_size=300,\n",
    "            filter_sizes=[3,4,5],\n",
    "            num_filters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_weights = [x for x in tf.global_variables() if \"embedding\" in str(x)]\n",
    "other_weights = [x for x in tf.global_variables() if \"embedding\" not in str(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(other_weights)\n",
    "saver_embedding = tf.train.Saver(gensim_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output/gensim_weights\n"
     ]
    }
   ],
   "source": [
    "saver_embedding.restore(sess, model_folder + \"/gensim_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/model-100\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, \"runs/checkpoints/model-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl, gzip, pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    preprocessed  = []\n",
    "    for token in tokens:\n",
    "        if len(token) > 2 and token == token[0].upper() + token[1:].lower():\n",
    "            token = \"_PROPERNAME_\"\n",
    "        preprocessed.append(token.lower())\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_to_token_id(text):\n",
    "    tokens = preprocess(text)\n",
    "    ids = []\n",
    "    for t in tokens:\n",
    "        if t in abridged_word2index:\n",
    "            idx = abridged_word2index[t]\n",
    "        else: # _UNKNOWN_\n",
    "            idx = 0\n",
    "        ids.append(idx)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letter by Anne Brontë\n",
    "data= preprocess_to_token_id('''Sir,\n",
    "      Ill health must plead my excuse for this long delay in acknowledging your flattering communication; but, believe me, I am not the less gratified at the pleasure you have derived from my own and my relatives' works, especially from the opinions they express. I have seen so little of controversial Theology that I was not aware the doctrine of Universal Salvation had so able and ardent an advocate as yourself; but I have cherished it from my very childhood - with a trembling hope at first, and afterwards with a firm and glad conviction of its truth. I drew it secretly from my own heart and from the word of God before I knew that any other held it. And since then it has ever been a source of true delight to me to find the same views either timidly suggested or boldly advocated by benevolent and thoughtful minds; and I now believe there are many more believers than professors in that consoling creed. Why good men should be so averse to admit it, I know not; - into their own hearts at least, however they might object to its promulgation among the bulk of mankind. But perhaps the world is not ripe for it yet. I have frequently thought that since it has pleased God to leave it in darkness so long respecting this particular truth, and often to use such doubtful language as to admit of such a general misconception thereupon, he must have some good reason for it. We see how liable men are to yield to the temptations of the passing hour; how little the dread of future punishment - how still less the promise of future reward can avail to make them forbear and wait; and if so many thousands rush into destruction with (as they suppose) the prospect of Eternal Death before their eyes, - what might not the consequence be, if that prospect were changed for one of a limited season of punishment, far distant and unseen, - however protracted and terrible it might be? \n",
    "      I thankfully cherish this belief; I honour those who hold it; and I would that all men had the same view of man's hopes and God's unbounded goodness as he had given to us, if it might be had with safety. But does not that if require some consideration? should we not remember the weak brother and the infatuated slave of satan, and beware of revealing these truths too hastily to those as yet unable to receive them? But in these suggestions I am perhaps condemning myself, for in my late novel, 'The Tenant of Wildfell Hall', I have given as many hints in support of the doctrine as I could venture to introduce into a work of that description. They are however mere suggestions, and as such I trust you will receive them, believing that I am well aware how much may be said in favour of boldly disseminating God's truth and leaving that to work its way. Only let our zeal be tempered with discretion, and while we labour, let us humbly look to God who is able and certain to bring his great work to perfection in his own good time and manner. \n",
    "      Accept my best wished in behalf of yourself and your important undertakings, and believe me to remain with sincere esteem\n",
    "\n",
    "Yours truly \n",
    "        Acton Bell.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Letter by Charlotte Bronte\n",
    "data= preprocess_to_token_id('''all I know – is that I cannot – that I will not resign myself to the total loss of my master’s friendship – I would rather undergo the greatest bodily pains that have my heart constantly lacerated by searing regrets. If my master withdraws his friendship from me entirely I shall be absolutely without hope – if he gives me a little friendship – a very little – I shall be content – happy, I would have a motive for living – for working.       Monsieur, the poor do not need a great deal to live on – they ask only the crumbs of bread which fall from the rich men’s table – but if they are refused these crumbs - they die of hunger -  No more do I need a great deal of affection from those I love – I would not know what to do with a whole and complete friendship – I am not accustomed to it – but you showed a little interest in me in days gone by when I was your pupil in Brussels – and I cling to the preservation of this little interest – I cling to it as I would cling on to life.\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_cnn(text_preprocessed_gensim):\n",
    "    input_data = []\n",
    "    if len(text_preprocessed_gensim) < SAMPLE_LENGTH:\n",
    "        input_data.append([])\n",
    "        for i in range(10):\n",
    "            input_data[0].extend(text_preprocessed_gensim)\n",
    "            if len(input_data[0]) > SAMPLE_LENGTH:\n",
    "                input_data[0] = input_data[0][:SAMPLE_LENGTH]\n",
    "                break\n",
    "    else:\n",
    "        for i in range(0, len(text_preprocessed_gensim) - SAMPLE_LENGTH - 1, 100):\n",
    "            input_data.append(text_preprocessed_gensim[i:i+SAMPLE_LENGTH])\n",
    "    \n",
    "        \n",
    "    result = sess.run(cnn.scores, {cnn.input_x: input_data, cnn.dropout_keep_prob: 1.0})\n",
    "    \n",
    "    proba_result = []\n",
    "    for result_segment in result:\n",
    "        probas = [np.exp(x) for x in result_segment]\n",
    "        probas /= sum(probas)\n",
    "        proba_result.append(probas)\n",
    "    \n",
    "    return np.asarray(proba_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43884012, 0.35928553, 0.20187436]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = execute_cnn(data)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
